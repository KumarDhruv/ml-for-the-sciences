{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " ## Multi-band detection by pixel-level clustering\n",
    "\n",
    "[*This is not a thorough application, more a quick test if the idea has merit. And we'll do some serious harm to error propagationâ€¦*].\n",
    "\n",
    "Traditionally astronomical image analysis is performed in individual bands. You take an image, say in the optical $r-$band, detect objects there, and determine their properties. If you have multiple bands, you repeat the process for each band. That's weird because we naturally expect images to have colors. What if we did our analyses on multi-band image cubes? We'd have more information and access to alternative ways of looking at the data. And we could play with analysis methods that are often associated with catalog-level data, but this time we use them directly on pixels.\n",
    "\n",
    "I will attempt to do detection and segmentation (finding out which pixel belong to which object) by looking for pixels with similar colors, in other words *clustering* in a suitable color space. I made an example image with 3 objects in a 3-band image cube: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.aspect'] = 'equal'\n",
    "plt.rcParams['figure.figsize'] = [6,6]\n",
    "\n",
    "def rgb_arcsinh_scaling(img, zero=0):\n",
    "    img_tot = img.sum(axis=0)\n",
    "    # combine to RGB cube with arcsinh scaling\n",
    "    scaled = np.arcsinh((img_tot-zero)/np.std(img_tot)*5)\n",
    "    scaled = (scaled - scaled.min()) / (scaled.max() - scaled.min())\n",
    "    # needs to be a (N,M,3)\n",
    "    rgb = np.moveaxis(img[::-1,:,:] * (scaled / img_tot)[None,:,:], 0,2)\n",
    "    return rgb\n",
    "\n",
    "# load simulated 3-band image:\n",
    "img = np.load(\"3-band-example.npy\").astype('float')\n",
    "B,Ny,Nx = img.shape\n",
    "sky = 100\n",
    "rgb = rgb_arcsinh_scaling(img, zero=sky*B)\n",
    "plt.figure()\n",
    "plt.imshow(rgb)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What you get is the traditional way of looking at it as false-color image (with a visually pleasing arcsinh stretch), which is ordered by pixel position. But what about flipping this: the same data, but now ordered by intensity in $gri$, each dot is one pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the 3-band color space\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(img[0].flatten(), img[1].flatten(), img[2].flatten())\n",
    "ax.set_xlabel('g')\n",
    "ax.set_ylabel('r')\n",
    "ax.set_zlabel('i')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One can see three distinct groups of pixels, distributed along straight lines of different direction. That's because the relative amplitude in different bands is the same (modulo noise), but the overall intensity is changing. The brightest pixels of each object is at the tip of each branch. The three branches merge in one common point, which is the sky intensity.\n",
    "\n",
    "Before we attempt a clustering analysis, we might want to do a dimensionality reduction. After all, these straight lines are entirely predictable. I tried several methods from scikit-learn, but none worked satisfactorily. If someone knows a reduction technique in scikit-learn that compresses those linear branches to points, let me know! In the meantime, we have to think of something else.\n",
    "\n",
    "A transformation that nulls the intensity variation is to normalize by the sum of intensities in all bands $b$:\n",
    "$$\n",
    "I^\\prime_{b,i,j} = I_{b,i,j} \\Big/ \\sum_b I_{b,i,j}\n",
    "$$\n",
    "Now all samples have $\\sum_b I^\\prime_{b,i,j}=1$ in intensity space, a constraint that is called a [simplex](https://en.wikipedia.org/wiki/Simplex). But we're still in 3D. However, since the \"length\" of the intensity vectors is irrelevant, only the direction matters. We can go the origin of the intensity space, $(0,0,0)$ in the right image above, and project out the length direction. That's equivalent to looking at the sky and ignoring the distances to all stars/galaxies. I will call the resulting space the **color space**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def simplex_projection(img):\n",
    "    # normalize total intensity\n",
    "    img_tot = img.sum(axis=0)\n",
    "    # yeah: division by zero happens here!\n",
    "    v = img.astype('float') / img_tot[None,:,:]\n",
    "\n",
    "    # build basis of simplex\n",
    "    d = img.shape[0]\n",
    "    basis = np.zeros((d,d))\n",
    "    # set normal on simplex\n",
    "    basis[:,0] = 1\n",
    "    for i in xrange(1,d):\n",
    "        basis[0,i] = -1\n",
    "        basis[i,i] = 1\n",
    "    q,r = np.linalg.qr(basis)\n",
    "\n",
    "    # remove projection onto normal\n",
    "    w = q[:,1:].T\n",
    "    v = np.einsum('ij,j...', w, v)\n",
    "    return v\n",
    "\n",
    "# project 3-band data onto 2-dim simplex\n",
    "v = simplex_projection(img)\n",
    "v = v.reshape(-1,2)\n",
    "# plot the 2D distribution: surface of simplex\n",
    "plt.figure()\n",
    "sc = plt.scatter(v[:,0], v[:,1], alpha=0.1)\n",
    "plt.xlabel('$v_1$')\n",
    "plt.ylabel('$v_2$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The big blob in the center the color of the sky. I used 100 counts in every band, so the sky color is gray, and it's at the center of the simplex. Every color in the image is a mixture of the sky color and the color of one or several objects, the relative ratios create the branches in the left panel. The brightest pixels of each objects are still at the tips of the branches.\n",
    "\n",
    "To get rid of the sky, one can subtract it before projecting onto the simplex. **But that causes the mean of the denominator of the simplex normalization to be zero!** Division by zero or very small numbers is usually not a good idea, but let's try anyway. What you get is the right panel above *if you trim it to 2D distances of <0.75* (that number is hand-picked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for better separation: remove the sky\n",
    "v = simplex_projection(img-sky)\n",
    "v = v.reshape(-1,2)\n",
    "# exclude \"bad\" pixels\n",
    "sel = np.isnan(v[:,0]) | np.isnan(v[:,1])\n",
    "# prune the noise\n",
    "noise_thresh = 0.75\n",
    "sel |= (v**2).sum(axis=1) > noise_thresh\n",
    "v_ = v[~sel]\n",
    "\n",
    "# plot the 2D distribution: surface of simplex\n",
    "plt.figure()\n",
    "colors = np.array([[0,0,0], sc.get_facecolors()[0]])\n",
    "plt.scatter(v[:,0], v[:,1], alpha=0.1, c=colors[(~sel).astype('int')])\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.yticks(plt.xticks()[0])\n",
    "plt.xlabel('$v_1$')\n",
    "plt.ylabel('$v_2$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There are many outliers (black markers) whose color are very close to the sky, so their color after subtraction becomes rather ill-defined. Nonetheless, the brighter pixels here form three groups, two of which quite strongly overlap. But that should be good enough to run a simple clustering algorithm. Following the decision tree from scikit-learn I picked the simplest one, $k$-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "labels_ = kmeans.fit_predict(v_)\n",
    "# get lables for every sample, even outliers (assigned label =0)\n",
    "labels = np.zeros(len(v), dtype='int')\n",
    "labels[~sel] = labels_ + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK, that was easy. But was it any good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plotWithLabels(v, labels):\n",
    "    # get peak colors for labels later\n",
    "    xs = 10,15,30\n",
    "    ys = 10,35,25\n",
    "    pos = zip(ys,xs)\n",
    "    colors = np.array([np.array([0,0,0])] + [rgb[y,x,:] for (y,x) in pos])\n",
    "\n",
    "    # align the labels with the peak order from the image, so that colors match\n",
    "    pixel_labels = labels.reshape((Ny,Nx))\n",
    "    peak_labels = [pixel_labels[y,x] for (y,x) in pos]\n",
    "    labels_ = labels.copy()\n",
    "    for k in range(len(pos)):\n",
    "        mask = labels == peak_labels[k]\n",
    "        labels_[mask] = k + 1\n",
    "    plt.figure()\n",
    "    plt.scatter(v[:,0], v[:,1], c=colors[labels_], alpha=0.3)\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.yticks(plt.xticks()[0])\n",
    "    plt.xlabel('$v_1$')\n",
    "    plt.ylabel('$v_2$')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure()\n",
    "    segmentation = np.zeros((Ny,Nx,3))\n",
    "    for k in range(len(pos)):\n",
    "        mask = pixel_labels == peak_labels[k]\n",
    "        segmentation[mask] = colors[k + 1]\n",
    "    plt.imshow(segmentation)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotWithLabels(v, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Well, $k$-means found a clustering in color space that looks plausible. I used the colors that correspond to the ones in the original image. I ran this a few times and the only aspect that changes is the boundary between the cyan and blue cluster. Not surprising, since these objects have similar colors.\n",
    "\n",
    "Using those color-based labels, we can now ask: which pixel belongs to which object in the image (right panel). We can see that, by and large, the detection and segmentation is indeed quite plausible. The brighter pixels are correctly associated with a single object. Black pixels in this image are the ones we needed to exclude as outliers before, and indeed they are preferentially from regions that should be mostly sky.\n",
    "\n",
    "This concludes my simple example of multi-band detection by color only. Note that we didn't use any spatial information, and still we got something that makes sense. Color is a powerful discriminator!\n",
    "\n",
    "Do you have ideas how to improve upon that?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
